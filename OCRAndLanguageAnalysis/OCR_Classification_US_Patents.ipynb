{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the first attempt at OCR'ing US patents. It times the OCR process and creates baseline versions of the text file for US Patents in a parallel fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "import os\n",
    "from pdf2image import convert_from_path, convert_from_bytes\n",
    "from pdf2image.exceptions import (\n",
    "    PDFInfoNotInstalledError,\n",
    "    PDFPageCountError,\n",
    "    PDFSyntaxError\n",
    ")\n",
    "import cv2 \n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import PyPDF2 as pyPdf\n",
    "import time\n",
    "import random\n",
    "import ocrutils\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch all TIF's and organize them in a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch all paths to tif's\n",
    "tifs = []\n",
    "for path, dirs, files in os.walk(\"/Volumes/Non-Backup_Files/US-patents/\"):\n",
    "    for f in files:\n",
    "        if f.endswith('tif'):\n",
    "            tifs.append('{}/{}'.format(path, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_dict = {}\n",
    "for tif_path in tifs:\n",
    "    if '/00/' in tif_path and ''.join(tif_path.split('/')[-3:-1]).isdigit():\n",
    "#         print(tif_path)\n",
    "#         print(int(''.join(tif_path.split('/')[-3:-1])))\n",
    "        if int(''.join(tif_path.split('/')[-3:-1])) in patent_dict:\n",
    "            patent_dict[int(''.join(tif_path.split('/')[-3:-1]))].append(tif_path)\n",
    "        else:\n",
    "            patent_dict.update({int(''.join(tif_path.split('/')[-3:-1])): [tif_path]})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_patents = list(patent_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/Non-Backup_Files/US-patents/17900731_18641101_yb2_D00001/00000001-X009741H/00/000/003/00000001.tif',\n",
       " '/Volumes/Non-Backup_Files/US-patents/17900731_18641101_yb2_D00001/00000001-X009741H/00/000/003/00000002.tif',\n",
       " '/Volumes/Non-Backup_Files/US-patents/17900731_18641101_yb2_D00001/00000001-X009741H/00/000/003/00000003.tif',\n",
       " '/Volumes/Non-Backup_Files/US-patents/17900731_18641101_yb2_D00001/00000001-X009741H/00/000/003/00000004.tif']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_patents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "674807"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(us_patents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OCR_US_patent(patent_nb_index, patent_dict, patent_list, output_path='/Volumes/Non-Backup_Files/US-patents/MachineReadableBaseline'):\n",
    "    \"\"\"\n",
    "    function to OCR a US patent\n",
    "    Args:\n",
    "    patent_nb_index - the index of the patent number in the patent list\n",
    "    patent_dict - a dictionary such that the keys are patent numbers and the values are lists of the paths to the tif files of the patent number\n",
    "    patent_list - a list containg the patent numbers\n",
    "    output_path - the path to put the output in\n",
    "    Returns:\n",
    "    None but the function writes the text file in the output file\n",
    "    \"\"\"\n",
    "    patent_str = ''\n",
    "    patent_nb = patent_list[patent_nb_index]\n",
    "    \n",
    "    for img_index in range(len(patent_dict[patent_nb])):\n",
    "        img = Image.open(patent_dict[patent_nb][img_index])\n",
    "        str_from_img = pytesseract.image_to_string(img)\n",
    "        patent_str = '{}\\n{}'.format(patent_str, str_from_img)\n",
    "        \n",
    "    with open('{}/{}.txt'.format(output_path, patent_nb), \"w\") as text_file:\n",
    "        text_file.write(\"%s\" % patent_str)\n",
    "        \n",
    "def OCR_US_patent_list(patent_dict, patent_list, timed=False, output_path='/Volumes/Non-Backup_Files/US-patents/MachineReadableBaseline'):\n",
    "    \"\"\"\n",
    "    function to OCR a list of US patents\n",
    "    Args:\n",
    "    patent_dict - a dictionary such that the keys are patent numbers and the values are lists of the paths to the tif files of the patent number\n",
    "    patent_list - a list containg the patent numbers\n",
    "    timed - whether to time each OCR process\n",
    "    output_path - the path to put the output in\n",
    "    Returns:\n",
    "    a list of the times it took to OCR each patent if timed is True, None otherwise\n",
    "    but the function writes the text file in the output file\n",
    "    \"\"\"\n",
    "    if not timed:\n",
    "        for patent_nb_index in range(len(patent_list)):\n",
    "            OCR_US_patent(patent_nb_index, patent_dict, patent_list, output_path)\n",
    "            if(patent_nb_index % 1000 == 0):\n",
    "                print('finished {}'.format(patent_nb_index))\n",
    "    else:\n",
    "        times = []\n",
    "        for patent_nb_index in range(len(patent_list)):\n",
    "            start = time.time()\n",
    "            OCR_US_patent(patent_nb_index, patent_dict, patent_list, output_path)\n",
    "            end = time.time()\n",
    "            times.append(end - start)    \n",
    "            if(patent_nb_index % 1000 == 0):\n",
    "                print('finished {}'.format(patent_nb_index))\n",
    "        return times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR on small random sample to get an idea of complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 0\n"
     ]
    }
   ],
   "source": [
    "test_list = random.sample(patent_dict.keys(), 15)\n",
    "times = OCR_US_patent_list(patent_dict, test_list, timed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8240856.361843363"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_times = 0\n",
    "for i in times:\n",
    "    sum_times += i\n",
    "sum_times/len(times) * len(us_patents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would need about 3 months to cover all patents. Let's parallelize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = random.sample(patent_dict.keys(), 15)\n",
    "result_objects = [pool.apply_async(ocrutils.OCR_US_patent, args=(i, patent_dict, test_list)) for i in range(len(test_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "[r.get() for r in result_objects]\n",
    "end = time.time()\n",
    "delay = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4557169.918809716"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay/len(test_list) * len(us_patents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.753293784459432"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay/len(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would take about a month and a half to OCR all the patents. Let's take a subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take random sample of patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeded_list = random.sample(patent_dict.keys(), 2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "for patent_number in seeded_list:\n",
    "    os.mkdir('/Volumes/Non-Backup_Files/US-patents/random_sample_seeded/{}'.format(patent_number))\n",
    "    for img_path in patent_dict[patent_number]:\n",
    "        copyfile(img_path, '/Volumes/Non-Backup_Files/US-patents/random_sample_seeded/{}/{}'.format(patent_number, img_path.split('/')[-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch all paths to tif's\n",
    "seeded_list = []\n",
    "for path, dirs, files in os.walk(\"/Volumes/Non-Backup_Files/US-patents/random_sample_seeded\"):\n",
    "    for f in files:\n",
    "        if f.endswith('tif'):\n",
    "            seeded_list.append('{}/{}'.format(path, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeded_dict = {}\n",
    "for patent_nb in os.listdir(\"/Volumes/Non-Backup_Files/US-patents/random_sample_seeded\"):\n",
    "    for patent_nb_pg in os.listdir(\"/Volumes/Non-Backup_Files/US-patents/random_sample_seeded/{}\".format(patent_nb)):\n",
    "        if int(patent_nb) in seeded_dict.keys():\n",
    "            seeded_dict[int(patent_nb)].append(\"/Volumes/Non-Backup_Files/US-patents/random_sample_seeded/{}/{}\".format(patent_nb,patent_nb_pg))\n",
    "        else:\n",
    "            seeded_dict.update({int(patent_nb): [\"/Volumes/Non-Backup_Files/US-patents/random_sample_seeded/{}/{}\".format(patent_nb,patent_nb_pg)]})\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeded_key_list = list(seeded_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_objects = [pool.apply_async(ocrutils.OCR_US_patent, args=(i, seeded_dict, seeded_key_list, \"/Volumes/Non-Backup_Files/US-patents/random_sample_seeded_txt\")) for i in range(len(seeded_key_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error setting from dictionary",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/andrealphonse/anaconda/envs/patentproj/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/andrealphonse/Documents/UniStuff/MA/MA3/Classes/Patent Project/PatentAnalysis/ocrutils.py\", line 41, in OCR_US_patent\n    str_from_img = pytesseract.image_to_string(img)\n  File \"/Users/andrealphonse/anaconda/envs/patentproj/lib/python3.6/site-packages/pytesseract/pytesseract.py\", line 374, in image_to_string\n    }[output_type]()\n  File \"/Users/andrealphonse/anaconda/envs/patentproj/lib/python3.6/site-packages/pytesseract/pytesseract.py\", line 373, in <lambda>\n    Output.STRING: lambda: run_and_get_output(*args),\n  File \"/Users/andrealphonse/anaconda/envs/patentproj/lib/python3.6/site-packages/pytesseract/pytesseract.py\", line 271, in run_and_get_output\n    with save(image) as (temp_name, input_filename):\n  File \"/Users/andrealphonse/anaconda/envs/patentproj/lib/python3.6/contextlib.py\", line 81, in __enter__\n    return next(self.gen)\n  File \"/Users/andrealphonse/anaconda/envs/patentproj/lib/python3.6/site-packages/pytesseract/pytesseract.py\", line 196, in save\n    image.save(input_file_name, format=image.format)\n  File \"/Users/andrealphonse/anaconda/envs/patentproj/lib/python3.6/site-packages/PIL/Image.py\", line 2151, in save\n    save_handler(self, fp, filename)\n  File \"/Users/andrealphonse/anaconda/envs/patentproj/lib/python3.6/site-packages/PIL/TiffImagePlugin.py\", line 1621, in _save\n    e = Image._getencoder(im.mode, \"libtiff\", a, im.encoderconfig)\n  File \"/Users/andrealphonse/anaconda/envs/patentproj/lib/python3.6/site-packages/PIL/Image.py\", line 462, in _getencoder\n    return encoder(mode, *args + extra)\nRuntimeError: Error setting from dictionary\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0146a34c086c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_objects\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0146a34c086c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_objects\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/patentproj/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error setting from dictionary"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "[r.get() for r in result_objects]\n",
    "end = time.time()\n",
    "delay = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open('/Users/andrealphonse/Downloads/00000002.png')\n",
    "# str_from_img = pytesseract.image_to_string(img)\n",
    "# with open('TesseractTest_430/02.txt', \"w\") as text_file:\n",
    "#     text_file.write(\"%s\" % str_from_img)\n",
    "# img = Image.open('/Users/andrealphonse/Downloads/00000001.png')\n",
    "# str_from_img = pytesseract.image_to_string(img)\n",
    "# with open('TesseractTest_430/01.txt', \"w\") as text_file:\n",
    "#     text_file.write(\"%s\" % str_from_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweaking OCR and some NLP trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import neuralcoref\n",
    "import autocorrect\n",
    "from autocorrect import Speller\n",
    "spell = Speller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG_PATH = '/Volumes/Non-Backup_Files/US-patents/random_sample_seeded/430/00000001.tif'\n",
    "# TEXT_PATH = '/Volumes/Non-Backup_Files/US-patents/random_sample_seeded/430/00000002.tif'\n",
    "FIG_PATH = '/Volumes/Non-Backup_Files/US-patents/random_sample_seeded/604/00000001.tif'\n",
    "TEXT_PATH = '/Volumes/Non-Backup_Files/US-patents/random_sample_seeded/604/00000002.tif'\n",
    "fig_im = Image.open(FIG_PATH)\n",
    "text_im = Image.open(TEXT_PATH)\n",
    "fig_array = np.array(fig_im)\n",
    "text_array = np.array(text_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_str = pytesseract.image_to_string(text_array, config='--psm 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‘\n",
      "\n",
      "Unrrep STATES\n",
      "\n",
      "PaTENT OFFICE.\n",
      "\n",
      " \n",
      "\n",
      "WILLIAMS T. SPROUSE, OF SANGAMON, ILLINOIS.\n",
      "\n",
      "‘IMPROVEMENT IN PLOWS.\n",
      "\n",
      "Specification forming part of Letters Patent No. 604, dated February 15, 1838.\n",
      "\n",
      " \n",
      "\n",
      "To all whom it may concern:\n",
      "\n",
      "Be it known that I, WiLL1Ams T, SPROUSE,\n",
      "of the county of Sangamon and State of Ili-\n",
      "- nois, have discovered a new and useful Im-\n",
      "provement in the Manutacture of Plows; and\n",
      "i do hereby declare that the following is a full\n",
      "and exact description of said improvement and\n",
      "of the process of making the same.\n",
      "\n",
      "The improved: plow is called “Sprouse’s\n",
      "\n",
      "plow,” and. differs from all other plows in the\n",
      "\n",
      "manner as wellof making the-irons as of stock-\n",
      "ing them, the mold-board and bar being made\n",
      "out of a single piece of iron without welding,\n",
      "thus: Take a plow-plate, square at one end\n",
      "and of the proper dimensions—say twelve (12)\n",
      "inches broad, the upper edge eighteen (18)\n",
      "inches, and the lower ed geor share twelve (12)\n",
      "inches long. Draw a diagonal line across said\n",
      "plate from a poiut on the upper edge thereof\n",
      "six (6) inches from the square and twelve (12)\n",
      "inches from the sharp end of said upper edge\n",
      "to the square end of. the lower edge of said\n",
      "plate, leaving the said plate on one side of said\n",
      "line in the shapeof a diamond and on the other\n",
      "side of a half-square.. Cut through the plate\n",
      "ou this line, one-half the distance thereof, com-\n",
      "mencing on theupper edge ofsaid plate. Make\n",
      "\n",
      "a half-inch hole through said plate, ou each side\n",
      "of said diagonal line, about one and a half\n",
      "inch from the upper edge of the plate. Bend\n",
      "the smaller part of the plate—to wit, that in\n",
      "the shape of a half-square, detached, as afore-\n",
      "\n",
      "said—by cutting, over into the proper position\n",
      "forthebar. Givethelarger—i. e. the diamond-\n",
      "shaped—part of the plate a gradual bend for a\n",
      "\n",
      "‘mold-board, and the irons are completed.\n",
      "\n",
      "The stock is made upon the same principle .\n",
      "\n",
      "‘that stocks of other plows are made, consist-\n",
      "ring of a sheth and two handles.\n",
      "\n",
      "The plow is stocked thus: The sheth H is\n",
      "placed under the mold, and is attached to the\n",
      "\n",
      "“bar and ‘mold respectively by volts passing\n",
      "\n",
      "through the holes directed to be made in said\n",
      "bar and mold, the bolt ihrough the bar being\n",
      "extended through. the sheth and fastened by\n",
      "a tap, and that through the mold extending\n",
      "also through and.attaching the lelt-hand han-\n",
      "dle to. the sheth, aud thus being fastened by a\n",
      "tap. The right-hand handle is attached to the\n",
      "sheth by # staple.\n",
      "\n",
      "What I, the said WILLIAMS .T. SPROUSE,\n",
      "claim as my own invention, and not previously\n",
      "‘known, in the above-described improvement\n",
      "in the manufacture of plows, is—\n",
      "\n",
      "The making of the mold and bar out of a.\n",
      "single piece of iron by cutting and bending\n",
      "instead of making them out of two pieces of -\n",
      "iron and welding tliem together.\n",
      "\n",
      "Springfield, November 30, 1836. _\n",
      "\n",
      "WILLIAMS T. SPROUSE.\n",
      "\n",
      "_ in presence of—\n",
      "JESSE B. THOMAS, Jr.\n",
      "JAMES BARKINSON,\n",
      "\n",
      " \n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "print(patent_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP to detect claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spell(\"I'm not sleapy and tehre is no place I'm giong to.\")\n",
    "# \"I'm not sleepy and there is no place I'm going to.\"\n",
    "patent_str_corr = spell(patent_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‘\n",
      "\n",
      "Unfree STATES\n",
      "\n",
      "PaTENT OFFICE.\n",
      "\n",
      " \n",
      "\n",
      "WILLIAM T. SPROUSE, Of SANGAMON, ILLINOIS.\n",
      "\n",
      "‘IMPROVEMENT In PLOS.\n",
      "\n",
      "Specification forming part of Letters Patent No. 604, dated February 15, 1838.\n",
      "\n",
      " \n",
      "\n",
      "To all whom it may concern:\n",
      "\n",
      "Be it known that I, With1As T, SPROUSE,\n",
      "of the county of Sangamon and State of Ili-\n",
      "- ois, have discovered a new and useful Im-\n",
      "movement in the Manufacture of Flows; and\n",
      "i do hereby declare that the following is a full\n",
      "and exact description of said improvement and\n",
      "of the process of making the same.\n",
      "\n",
      "The improved: plow is called “Spouse’s\n",
      "\n",
      "plow,” and. differs from all other flows in the\n",
      "\n",
      "manner as well making the-irons as of stock-\n",
      "ing them, the mold-board and bar being made\n",
      "out of a single piece of iron without welding,\n",
      "thus: Take a plow-plate, square at one end\n",
      "and of the proper dimensions—say twelve (12)\n",
      "inches broad, the upper edge eighteen (18)\n",
      "inches, and the lower ed geo share twelve (12)\n",
      "inches long. Draw a diagonal line across said\n",
      "plate from a point on the upper edge thereof\n",
      "six (6) inches from the square and twelve (12)\n",
      "inches from the sharp end of said upper edge\n",
      "to the square end of. the lower edge of said\n",
      "plate, leaving the said plate on one side of said\n",
      "line in the shape a diamond and on the other\n",
      "side of a half-square.. Cut through the plate\n",
      "ou this line, one-half the distance thereof, com-\n",
      "fencing on theupper edge said plate. Make\n",
      "\n",
      "a half-inch hole through said plate, ou each side\n",
      "of said diagonal line, about one and a half\n",
      "inch from the upper edge of the plate. Bend\n",
      "the smaller part of the plate—to wit, that in\n",
      "the shape of a half-square, detached, as fore-\n",
      "\n",
      "said—by cutting, over into the proper position\n",
      "forthebar. Givethelarger—i. e. the diamond-\n",
      "shaped—part of the plate a gradual bend for a\n",
      "\n",
      "‘mold-board, and the irons are completed.\n",
      "\n",
      "The stock is made upon the same principle .\n",
      "\n",
      "‘that stocks of other flows are made, consist-\n",
      "ring of a seth and two handles.\n",
      "\n",
      "The plow is stocked thus: The seth H is\n",
      "placed under the mold, and is attached to the\n",
      "\n",
      "“bar and ‘mold respectively by volts passing\n",
      "\n",
      "through the holes directed to be made in said\n",
      "bar and mold, the bolt through the bar being\n",
      "extended through. the seth and fastened by\n",
      "a tap, and that through the mold extending\n",
      "also through and.attaching the left-hand han-\n",
      "dle to. the seth, aud thus being fastened by a\n",
      "tap. The right-hand handle is attached to the\n",
      "seth by # staple.\n",
      "\n",
      "What I, the said WILLIAM .T. SPROUSE,\n",
      "claim as my own invention, and not previously\n",
      "‘known, in the above-described improvement\n",
      "in the manufacture of flows, is—\n",
      "\n",
      "The making of the mold and bar out of a.\n",
      "single piece of iron by cutting and bending\n",
      "instead of making them out of two pieces of -\n",
      "iron and welding time together.\n",
      "\n",
      "Springfield, November 30, 1836. _\n",
      "\n",
      "WILLIAM T. SPROUSE.\n",
      "\n",
      "_ in presence of—\n",
      "SSE B. HMAS, Jr.\n",
      "AES BARKINSON,\n",
      "\n",
      " \n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "print(patent_str_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "example_doc = nlp(patent_str_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "nounIndices = []\n",
    "for token in example_doc:\n",
    "    # print(token.text, token.pos_, token.dep_, token.head.text)\n",
    "#     if token.pos_ == 'PRON':\n",
    "    if token.pos_ == 'VERB':\n",
    "        \n",
    "        nounIndices.append(index)\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN\n"
     ]
    }
   ],
   "source": [
    "print(example_doc[nounIndices[-5]:nounIndices[-5]+10][6].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forming\n",
      "dated\n",
      "may\n",
      "known\n",
      "discovered\n",
      "declare\n",
      "following\n",
      "said\n",
      "making\n",
      "called\n",
      "making\n",
      "ing\n",
      "made\n",
      "welding\n",
      "Take\n",
      "say\n",
      "share\n",
      "Draw\n",
      "said\n",
      "said\n",
      "leaving\n",
      "Cut\n",
      "fencing\n",
      "said\n",
      "Make\n",
      "said\n",
      "said\n",
      "Bend\n",
      "detached\n",
      "said\n",
      "cutting\n",
      "completed\n",
      "made\n",
      "made\n",
      "stocked\n",
      "placed\n",
      "attached\n",
      "passing\n",
      "directed\n",
      "made\n",
      "said\n",
      "extended\n",
      "fastened\n",
      "extending\n",
      "dle\n",
      "fastened\n",
      "attached\n",
      "said\n",
      "known\n",
      "described\n",
      "cutting\n",
      "making\n"
     ]
    }
   ],
   "source": [
    "for pronoun in nounIndices:\n",
    "#     if(example_doc[pronoun].text == 'claim'):\n",
    "    print(example_doc[pronoun])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[The improved: plow: [The plow, The improved: plow],\n",
       " the sheth: [the sheth, the sheth],\n",
       " one-half the distance: [one-half the distance, them]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_doc._.coref_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON  |  WILLIAMS T. SPROUSE\n",
      "GPE  |  SANGAMON\n",
      "GPE  |  ILLINOIS\n",
      "ORG  |  PLOWS\n",
      "WORK_OF_ART  |  Letters Patent No\n",
      "CARDINAL  |  604\n",
      "DATE  |  February 15, 1838\n",
      "PERSON  |  WittiAms T. SpRous\n",
      "GPE  |  Sangamon\n",
      "ORG  |  State\n",
      "GPE  |  the Manutacture of Plows\n",
      "CARDINAL  |  two\n",
      "WORK_OF_ART  |  Sprouse\n",
      "CARDINAL  |  twelve\n",
      "CARDINAL  |  12\n",
      "CARDINAL  |  18\n",
      "CARDINAL  |  twelve\n",
      "CARDINAL  |  12\n",
      "PERSON  |  WILLIAMS\n",
      "CARDINAL  |  six\n",
      "QUANTITY  |  6) inches\n",
      "CARDINAL  |  twelve\n",
      "CARDINAL  |  12\n",
      "CARDINAL  |  one\n",
      "QUANTITY  |  half-square\n",
      "CARDINAL  |  two\n",
      "CARDINAL  |  one-half\n",
      "GPE  |  Springfield\n",
      "DATE  |  November 30, 1836\n",
      "QUANTITY  |  half-inch\n",
      "CARDINAL  |  about one and a half\n",
      "PERSON  |  WALLIAMS T. SPROUSE\n",
      "PERSON  |  JESSE B. THOMAS,\n",
      "PERSON  |  JAMES BARKINSON\n"
     ]
    }
   ],
   "source": [
    "for entity in example_doc.ents:\n",
    "    print(entity.label_, ' | ', entity.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/andrealphonse/nltk_data'\n    - '/Users/andrealphonse/anaconda/envs/patentproj/nltk_data'\n    - '/Users/andrealphonse/anaconda/envs/patentproj/share/nltk_data'\n    - '/Users/andrealphonse/anaconda/envs/patentproj/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-ca7d429f4dae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"And now for something completely different\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/patentproj/lib/python3.6/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \"\"\"\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/patentproj/lib/python3.6/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/patentproj/lib/python3.6/site-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             AP_MODEL_LOC = \"file:\" + str(\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"taggers/averaged_perceptron_tagger/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mPICKLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             )\n\u001b[1;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/patentproj/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger/averaged_perceptron_tagger.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/andrealphonse/nltk_data'\n    - '/Users/andrealphonse/anaconda/envs/patentproj/nltk_data'\n    - '/Users/andrealphonse/anaconda/envs/patentproj/share/nltk_data'\n    - '/Users/andrealphonse/anaconda/envs/patentproj/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text = nltk.word_tokenize(\"And now for something completely different\")\n",
    "nltk.pos_tag(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patentproj",
   "language": "python",
   "name": "patentproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
